{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMYUaGkE6IL2W0UNo+bM47q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SimplySonu/Image-Classification-using-CNN/blob/main/Image_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7JfRESVPZ3T"
      },
      "source": [
        "<b>Image Classification Using Convolution Neural Network</b>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7K1kDJtwb1G"
      },
      "source": [
        "Importing required modules "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5MEBeHKPpwy"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCXsbwmKwavF"
      },
      "source": [
        "Loading the cifar10 dataset from keras and splitting it for training and testing\n",
        "<br>In this dataset there are 10 class labels to predict\n",
        "There are 50000 training records and 10000 testing records. \n",
        "<br>\n",
        "The class labels are listed below for reference.<br>\n",
        "1) airplane\t\t\t\t\t\t\t\t\t\n",
        "2) automobile\t\t\t\t\t\t\t\t\n",
        "3) bird\t\t\t\t\t\t\t\t\t\n",
        "4) cat\t\t\t\t\t\t\t\t\t\n",
        "5) deer\t\t\t\t\t\t\t\t\t\n",
        "6) dog\t\t\t\t\t\t\t\n",
        "7) frog\t\t\t\t\t\t\t\t\n",
        "8) horse\t\t\t\t\t\t\t\t\t\t\n",
        "9) ship\t\t\t\t\t\t\t\n",
        "10) truck"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpXBfoWnRYEn"
      },
      "source": [
        "#the cifar10 data is already splitted into training records and testing records\n",
        "(X_train,y_train), (X_test,y_test) = datasets.cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pq4ZuAn_b8PI"
      },
      "source": [
        "Exploring the the training and testing records using shape an reshape functions<br>\n",
        "so that we get a better overview on our dataset<br>\n",
        "shape function gives the shape of the dataset, \n",
        "<br>\n",
        "In the below given code we have the shape as <b>(50000,32,32,3)</b><br>\n",
        "where <b>50000</b> is the rows<br>\n",
        "<b>32x32</b> is the image matrix<br> \n",
        "and <b>3</b> signifies that it is a color image(RGB)   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yC6gINhmUXQs",
        "outputId": "f5de1ac3-47d1-4198-db92-063a778ab18f"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08tCnevt-Ds0"
      },
      "source": [
        "y train has only the output class i.e rows and class label so the shape is (50000,1), In which 50000 signifies rows and 1 is the column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKeQqQcCUcWF",
        "outputId": "c5b49bd9-6068-4e2d-bd98-b93f6b345b40"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZEqVDo9bR55",
        "outputId": "9a5551f6-164a-48e8-8dd6-5d43565ecf47"
      },
      "source": [
        "y_train[0:6]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6],\n",
              "       [9],\n",
              "       [9],\n",
              "       [4],\n",
              "       [1],\n",
              "       [1]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Se2S57mRa5Re",
        "outputId": "503cfc63-d69a-44d5-ce3f-e016b4fa08ff"
      },
      "source": [
        "#reshape function is used to reshape the array dimension\n",
        "y_train = y_train.reshape(-1,)\n",
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6, 9, 9, ..., 9, 1, 1], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F88Qdfx16mSd"
      },
      "source": [
        "Defining a function that takes X and Y values either it can be from training record or testing record for plotting a image<br>\n",
        "X implies image matrix ,\n",
        "y implies the class label,\n",
        "index implies the index of the class label which is been plotted "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0W9QRrJUnq8"
      },
      "source": [
        "def sample_image(X,y, index):\n",
        "  plt.figure(figsize=(14,2))\n",
        "  plt.imshow(X[index])\n",
        "  plt.xlabel(classes[y[index]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "HhXvpb-JZ7zo",
        "outputId": "84efd0ca-393e-4f35-bbc0-15b4b82f1724"
      },
      "source": [
        "#Ploting a image from training record\n",
        "sample_image(X_train, y_train, 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x144 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAlsMtucb_0u"
      },
      "source": [
        "<b>DATA NORMALIZAITON</b><br>\n",
        "Normalizing the values of training and testing records<br>\n",
        "I hav divided the values by 255 since the values of color ranges from 0 - 255 <br> Since this normalizaion would maxe the computation more feasible and easy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Lz3YvJkaGHK"
      },
      "source": [
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ztw4VK7O28u"
      },
      "source": [
        "Next step is to built our cnn model from keras library from model.sequentail function<br>\n",
        "<br>Sequential<br>\n",
        "A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor.<br>\n",
        "1) To the first layer we have added <b>Conv2D</b> matrix layer(A Convolutional neural network is a neural network that has one or more convolutional layers and are used mainly for image processing, classification, segmentation and also for other auto correlated data. A convolution is essentially sliding a filter over the input)<br> that takes the nuber of filters to be used, the filter size, activation function, inpute shape. <br>\n",
        "In our case we hav used 20 filters of size (2x2) matrix,<br> Relu activation function that is a linear function that will output the input directly if it is positive, otherwise, it will output zero, so basically it is an normalizing function,<br> and inpute shape(32x32x3) of our image that is shown in the above cell <br>\n",
        "<br>\n",
        "2) To the second layer i have used MaxPooling function for the pooliing layer that is of size (2x2) matrix<br>\n",
        "MaxPooling:-Max pooling is a sample-based discretization process. The objective is to down-sample an input representation (image, hidden-layer output matrix, etc.), reducing its dimensionality and allowing for assumptions to be made about features contained in the sub-regions binned\n",
        "\n",
        "3) i have repeated the first and and second step again(This step can be performed any numbers of time depending on our model)<br>\n",
        "NOTE:- <b>we need to pass the input shape only for the first time in Conv2D function </b> \n",
        "\n",
        "4)Next i have Flattend the matrix using Flatten function meaning -- converting the data into a 1-dimensional array for inputting it to the next layer. We flatten the output of the convolutional layers to create a single long feature vector. And it is connected to the final classification model, which is called a fully-connected layer.<br>\n",
        "<br>\n",
        "5) Next layer is the neural network layer <b>layer.dense(100,activation='relu')</b> that consist of 100 hidden neurons for updating the weights and i have used relu as the activation function.This layer helps the model to learn and predict the output accurately\n",
        "6) Last layer is the output layer <b>(layers.Dense(10,activation=\"softmax\"))</b> in which 10 specifies class label, and used a softmax activation function.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVDMKZmijnMr"
      },
      "source": [
        "cnn =  models.Sequential([\n",
        "                          #using convolution layer with 32 filters of size(3*3) and activation function \"relu\" and the input image of shape (32,32,3)\n",
        "                          #cnn layer\n",
        "                          #input_shape should be passed only in the initial layer of cnn\n",
        "                          layers.Conv2D(filters=20, kernel_size=(2,2), activation='relu',input_shape=(32,32,3)),\n",
        "                          layers.MaxPooling2D((2,2)),\n",
        "                          \n",
        "                          layers.Conv2D(filters=20, kernel_size=(2,2), activation='relu'),\n",
        "                          layers.MaxPooling2D((2,2)),\n",
        "                          layers.Flatten(),\n",
        "                          \n",
        "                          layers.Dense(100, activation='relu'), # hidden 64 neurons of dense layer 1\n",
        "                          layers.Dense(10,activation=\"softmax\")#output layer with 10 class labels \n",
        "\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgU0H1vmbR_K"
      },
      "source": [
        "Once the model is ready the next step is to compile and eavaluate the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_0R3-3gqc6B"
      },
      "source": [
        "cnn.compile(optimizer='adam',\n",
        "            loss='sparse_categorical_crossentropy',\n",
        "            metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g20sd9GibmTf"
      },
      "source": [
        "Next I have fit the model with training set and training the model for 20 epochs(iterations)<br>The Model is 83 percent accurate<br>\n",
        "And the model is ready to predict."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzVBhFZjr1kF",
        "outputId": "10cde2c9-1546-4922-daa2-befe968c295f"
      },
      "source": [
        "cnn.fit(X_train,y_train,epochs = 20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 1.7276 - accuracy: 0.3741\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 1.2845 - accuracy: 0.5437\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 1.1133 - accuracy: 0.6075\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 1.0269 - accuracy: 0.6387\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.9553 - accuracy: 0.6658\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.8913 - accuracy: 0.6875\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.8406 - accuracy: 0.7042\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.8015 - accuracy: 0.7196\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.7606 - accuracy: 0.7314\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.7111 - accuracy: 0.7525\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.6902 - accuracy: 0.7565\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.6553 - accuracy: 0.7715\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 0.6259 - accuracy: 0.7805\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.5939 - accuracy: 0.7912\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.5655 - accuracy: 0.8015\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.5500 - accuracy: 0.8070\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.5266 - accuracy: 0.8164\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.5079 - accuracy: 0.8221\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.4719 - accuracy: 0.8355\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 0.4577 - accuracy: 0.8399\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2af1a1a250>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHwXNnSAsUuv",
        "outputId": "3fc8a9d8-7dde-4f9e-fc21-4e540d53fd72"
      },
      "source": [
        "cnn.evaluate(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 7ms/step - loss: 1.1400 - accuracy: 0.6664\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.1400116682052612, 0.6664000153541565]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sMft5jk2QLT",
        "outputId": "ef5e9da1-1dd6-4ab9-8d43-fdee86ac2d01"
      },
      "source": [
        "#converting y_test record to one dimension\n",
        "y_test=y_test.reshape(-1,)\n",
        "y_test[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 8, 8, 0, 6], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgccwiIhcbR4"
      },
      "source": [
        "Next predict the labels of the data values on the basis of the trained model. The predict() function accepts only a single argument which is usually the data to be tested.<br>\n",
        "so i have predected for all the test record and displaying the first 5 image matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4co4LNeC2pBO",
        "outputId": "85769a85-3eec-4068-fb19-0c7fc9ce5a02"
      },
      "source": [
        "y_pred = cnn.predict(X_test)\n",
        "y_pred[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.07604409e-06, 1.05414565e-05, 5.05497737e-04, 3.59187841e-01,\n",
              "        1.33194306e-04, 6.39323294e-01, 7.90477381e-04, 3.80743295e-05,\n",
              "        4.14640544e-06, 1.84614316e-06],\n",
              "       [1.06819300e-03, 3.10044318e-01, 4.40227410e-09, 7.01811498e-09,\n",
              "        5.93541771e-10, 8.48194459e-10, 1.49296020e-10, 1.10582006e-08,\n",
              "        6.87827945e-01, 1.05957815e-03],\n",
              "       [7.91070890e-03, 1.96030773e-02, 7.30448710e-06, 2.87093317e-05,\n",
              "        1.45227386e-06, 3.31116837e-07, 6.55204668e-10, 1.45339880e-06,\n",
              "        9.55487728e-01, 1.69592053e-02],\n",
              "       [3.92428547e-01, 6.52367016e-04, 2.87988572e-03, 7.02368270e-04,\n",
              "        1.74936955e-03, 5.06824326e-05, 6.81657475e-05, 1.40533748e-05,\n",
              "        6.01330101e-01, 1.24412065e-04],\n",
              "       [1.31326274e-08, 1.41127521e-09, 3.97225143e-03, 4.98819798e-02,\n",
              "        2.15930194e-01, 1.04072233e-05, 7.30205178e-01, 2.61386788e-08,\n",
              "        1.54681743e-08, 5.08729343e-11]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhMu2aU4dHlV"
      },
      "source": [
        "Iterating over all the list of y_pred values that is of 2Dimension array and taxing only the index of the maximum value from all the list and storing it in a variable(y_predClass) and displaying the first five index value that the model has predicted"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOvfwhir29XV",
        "outputId": "4f3d615c-75ca-4230-81ec-1206e5b2815a"
      },
      "source": [
        "y_predClasses = [np.argmax(element) for element in y_pred]\n",
        "print(y_predClasses[0:5])\n",
        "print(y_test[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5, 8, 8, 8, 6]\n",
            "[3 8 8 0 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDGX626yePXG"
      },
      "source": [
        "The first five class label index that the model has predicted are <br>[5,8,8,8,6] and the actual class label index which is stored in y_test are <br>[3,8,8,0,6] <br>\n",
        "if we compare both the list we see that the model has correctly predicted 3 class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10w5-n9cftyJ"
      },
      "source": [
        "Let's see an example below\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "IrzN_Cge5aup",
        "outputId": "2a3e48bb-b84a-490f-cd74-77bb50eb85aa"
      },
      "source": [
        "#plotting image from test record of 11th index\n",
        "\n",
        "sample_image(X_test,y_test,11)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x144 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vEzw5vHhql7"
      },
      "source": [
        "The model has correctly predicted the image as truck"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Hsb84Xhs59I5",
        "outputId": "ff5e5255-d741-4712-9495-7809727e6758"
      },
      "source": [
        "#class that model has predicted for the 11th image from the test record \n",
        "classes[y_predClasses[11]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'truck'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlF3I1Ja6Ij5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}